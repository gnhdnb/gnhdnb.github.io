<!DOCTYPE html>
<html>
<body>
  <div style='margin: auto; text-align:justify; text-indent: 5%; width:800px; font-family: Verdana, Geneva, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: 400;'>
    <p>Nikita Prudnikov (<i>monekeer</i>) &mdash; musician, software architecture expert and DSP enthusiast currently working in the field of applied machine learning in its connection with the sound art. 
	    Nikita is an author of the <span style="white-space: nowrap;"><i><a href="https://github.com/gnhdnb/Flaky">F L A K Y</a></i></span> - a generative music framework which was used in <a href="https://soundcloud.com/monekeer/live-coding-equinox">live performances</a> on various events including: Ars Electronica, Gamma, Prepared Surroundings and others.</p>
	<h4>Selected works</h4>
	<p><i><a href="https://vimeo.com/523902056">Polyphonic</a></i> &mdash; a performance for a prepared harpsichord and a DIY spectral modeling synthesizer reflecting on the <a href="http://gnhdnb.github.io/polyphonic.pdf">theme of polyphony in nature</a>. Recorded in a duo with harpsichord player and baroque music expert Katarina Melik-Ovsepian.</p>
	<p><i><a href="https://faces2voices.live">Faces2Voices</a></i> &mdash; an online interactive installation which uses facial recognition technology and AI-synthesized sound to create a generative music composition based on imaginary voices of online visitors. A collaboration with new media artist Helena Nikonole.</p>
	<p><i><a href="https://youtu.be/TNb9PPRkHAA">“They” is here</a></i> &mdash; a research collaboration with a musician and artist Anastasia Tolchneva (lovozero) focused on the exploration of the sonic space between human and non-human. The result of this research is represented in a form of <i>fictional field recordings</i> which are synthesized using various AI techniques.</p>
	<p><i><a href="https://www.youtube.com/watch?v=bfqPcmwQEf0">Interpolations</a></i> &mdash; the novel machine interpretation of the Well-Tempered Clavier (<i>WTC</i>) by J.S. Bach performed in a duo with harpsichord player and baroque music expert Katarina Melik-Ovsepian. During the performance the duet explores the <i>latent space of bars</i> of the WTC through the process of the interpolation: the Neural Network generates a repetitive composition, interpreted by Katarina (harpsichord) and a specially designed synthesizer (AI-harpsichord).</p>
	<br/>
	<p><a href="https://soundcloud.com/monekeer">soundcloud</a> <a href="https://github.com/gnhdnb">github</a> <a href="https://twitter.com/gnhdnb">twitter</a></p>
  </div>
</body>
</html>
